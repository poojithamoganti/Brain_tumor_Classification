import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import plotly.graph_objects as go
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall
import os
from dotenv import load_dotenv
import numpy as np
import tensorflow as tf
from PIL import Image
import cv2
import google.generativeai as genai

output_dir = 'saliency_maps'
os.makedirs(output_dir, exist_ok=True)

try:
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("Google API key not found in environment variables")
    genai.configure(api_key=api_key)
except Exception as e:
    st.error(f"Failed to configure Google API: {str(e)}")



def generate_explanation(saliency_path, model_prediction, confidence):

    try:
        # Validate the path exists
        if not os.path.exists(saliency_path):
            st.error(f"Saliency map not found at: {saliency_path}")
            return None

        st.write("DEBUG: Opening saliency map from:", saliency_path)

        try:
            img = Image.open(saliency_path)
            #st.write("DEBUG: Successfully opened saliency map")
        except Exception as e:
            st.error(f"Failed to open saliency map: {str(e)}")
            return None

     


        prompt= f"""You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan, where a tumor is identified with a bounding box.
        The saliency map was generated by a deep learning model which was trained to classify brain tumors of four categories as either Giloma, Meningioma, pituitary or no tumor.
        
        
        The Saliency map highlights the regions of the image that the Machine learning model is focusiong on to make predictions.
        
        The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of '{confidence *100}%'.
        
        In your response:
        - Explain what regions of the brain the model is focusing on, based on the the saliency map. refer to the regions highlighted in light cyan and boundingbox,
        those are the regions where the model is focusing on.
        - Explain possible reasons why the model made the predictions it did.
        - Don't ever mention anything like ' The saliency map, highlights in light cyan , the model is focusing on or bounding box' in your explanation.
        - Keep your explanation concise, understandable to normal person and upto four sentences maximum.  
        
        Let's think step by step about this and verify step by step.
        
        """

        #st.write("DEBUG: Generating explanation with Gemini")
        model = genai.GenerativeModel(model_name="gemini-1.5-flash")
        response = model.generate_content([prompt, img])
        
        if not response or not response.text:
            st.error("Failed to generate explanation from Gemini API")
            return None

        #st.write("DEBUG: Successfully generated explanation")
        return response.text

    except Exception as e:
        st.error(f"Error in generate_explanation: {str(e)}")
        #st.write("DEBUG: Full error details:", str(e))
        return None
    

def generate_saliency_map(model, img_array, class_index, img_size):
    with tf.GradientTape() as tape:
        img_tensor = tf.convert_to_tensor(img_array)
        tape.watch(img_tensor)
        predictions = model(img_tensor)
        target_class = predictions[:, class_index]

    gradients = tape.gradient(target_class, img_tensor)
    gradients = tf.math.abs(gradients)
    gradients = tf.reduce_max(gradients, axis=-1)
    gradients = gradients.numpy()  
    gradients = gradients[0]  

    # Resize gradients to match original image size
    gradients = cv2.resize(gradients, img_size)

    # Create a circular mask for the brain area
    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
    radius = min(center[0], center[1]) - 10
    y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
    mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2

    # Apply mask to gradients
    gradients = gradients * mask

    # Normalize only the brain area
    brain_gradients = gradients[mask]
    if brain_gradients.max() > brain_gradients.min():
        brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
    gradients[mask] = brain_gradients

    # Apply a higher threshold
    threshold = np.percentile(gradients[mask], 80)
    binary_mask = gradients > threshold

    # Find contours of the thresholded region
    binary_mask = (binary_mask * 255).astype(np.uint8)
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Get original image
    original_img = img_array[0] * 255
    original_img = original_img.astype(np.uint8)
    
    # Create heatmap
    heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    heatmap = cv2.resize(heatmap, img_size)

    # Create output image with bounding box
    img_with_box = original_img.copy()

    if contours:
        # Find the largest contour (assumed to be the tumor)
        largest_contour = max(contours, key=cv2.contourArea)
        
        # Bounding Box
        x, y, w, h = cv2.boundingRect(largest_contour)
        cv2.rectangle(img_with_box, (x, y), (x+w, y+h), (255, 0, 0), 2)

    # Blend with heatmap
    superimposed_box = cv2.addWeighted(img_with_box, 0.7, heatmap, 0.3, 0)

    return superimposed_box




def preprocess_image(image_path, target_size=(160,160)):
    try:
        if isinstance(image_path, str):
            img = Image.open(image_path).convert("RGB")
        else:
            img = Image.open(image_path).convert("RGB")
        
        # Resize
        img = img.resize(target_size)
        
        # Convert to numpy array and add batch dimension
        img_array = np.asarray(img)
        img_array = img_array.astype('float32') / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        return img_array
    
    except Exception as e:
        st.error(f"Error in preprocessing: {str(e)}")
        return None



# Create nice spacing and layout
st.markdown("""
    <style>
        .main {
            padding: 2rem;
        }
        .title {
            text-align: center;
            margin-bottom: 2rem;
            color: #2e4057;
        }
        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 2rem;
        }
        .upload-section, .example-section {
            padding: 1.5rem;
            border-radius: 10px;
            background-color: #f8f9fa;
            margin-bottom: 1.5rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .stButton > button {
            width: 100%;
            padding: 10px 20px;
            font-size: 16px;
            margin: 10px 0;
            background-color: #4e89ae;
            color: white;
            font-weight: bold;
        }    
        .success-msg {
            padding: 1rem;
            border-radius: 5px;
            margin: 1rem 0;
        }
        .image-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 1rem;
            padding: 1rem 0;
        }
        .image-item {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
            background: white;
            padding: 1rem;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        .prediction-section {
            padding: 1.5rem;
            background-color: #ffffff;
            border-radius: 10px;
            margin-top: 2rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .confidence-bar {
            margin: 0.5rem 0;
        }
        .stProgress > div > div {
            background-color: #4e89ae;
        }
    </style>
""", unsafe_allow_html=True)

# Title with better spacing
st.markdown("<h1 style='text-align:center;'>üß† Brain Tumor Classification</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;'>Upload a brain MRI scan or choose from our examples for classification</p>", unsafe_allow_html=True)

# Upload Image Section
st.subheader("üì§ Upload Your Image")
uploaded_file = st.file_uploader("Choose an Image...",type=["jpg", "jpeg", "png"])



# Spacing between sections
st.markdown("<br><hr><br>", unsafe_allow_html=True)

# Choose from Examples Section
st.subheader("üîç Don't have an Image?? Choose from Below images!!!")

# Define example images
example_images = {
    "Glioma": "Dataset/Testing/glioma/Te-gl_0264.jpg",
    "Meningioma": "Dataset/Testing/meningioma/Te-me_0018.jpg",
    "No Tumor": "Dataset/Testing/notumor/Te-no_0018.jpg",
    "Pituitary": "Dataset/Testing/pituitary/Te-pi_0025.jpg"
}

# Initialize session state variables
if 'selected_example' not in st.session_state:
    st.session_state.selected_example = None
if 'selected_label' not in st.session_state:
    st.session_state.selected_label = None

# Create a 2x2 grid layout
cols = st.columns(2)
for idx, (label, path) in enumerate(example_images.items()):
    with cols[idx % 2]:
        if os.path.exists(path):
            img = Image.open(path).resize((150, 150))
            st.image(img, caption=label, use_column_width=False)
            if st.button(f"Select {label}", key=f"btn_{label}"):
                st.session_state.selected_example = path
                st.session_state.selected_label = label
                st.success(f"Selected: {label}")
                st.write(f"DEBUG: Selected image path is {st.session_state.selected_example}")


# Add spacing
st.markdown("<br>", unsafe_allow_html=True)


# Prediction section
st.markdown("<div class='prediction-section'>", unsafe_allow_html=True)
if st.button("üîÆ Predict"):
    try:
        img_path = None
        img_array = None
        
        # Handle image selection and create a unique path for saving
        import time
        timestamp = int(time.time())
        
        if uploaded_file is not None:
            #st.write("DEBUG: Processing uploaded file")
            # Save uploaded file with timestamp
            img_path = os.path.join(output_dir, f"input_image_{timestamp}.jpg")
            with open(img_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
        elif st.session_state.selected_example:
            #st.write("DEBUG: Processing selected example image")
            img_path = st.session_state.selected_example
        else:
            st.warning("‚ö†Ô∏è Please upload an image or select an example first.")
            st.stop()

        # Create a fixed path for saliency map
        saliency_path = os.path.join(output_dir, f"saliency_map_{timestamp}.jpg")
        
        # Preprocess image
        img_array = preprocess_image(img_path)
        if img_array is None:
            st.error("‚ùå Failed to preprocess image.")
            st.stop()

        # Model prediction
        with st.spinner('üîÑ Analyzing image...'):
            model = load_model("Model.h5")
            prediction = model.predict(img_array)
            labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']
            class_index = np.argmax(prediction[0])
            predicted_class = labels[class_index]
            confidence = float(np.max(prediction))

            # Display prediction results
            result_col1, result_col2 = st.columns([1, 1])
            with result_col1:
                st.markdown(f"""
                    <div style='text-align: center; padding: 1rem; background-color: #e3f2fd; border-radius: 10px;'>
                        <h2 style='color: #1976d2;'>{predicted_class}</h2>
                        <p style='font-size: 1.2rem;'>Predicted Class</p>
                    </div>
                """, unsafe_allow_html=True)

            with result_col2:
                st.markdown(f"""
                    <div style='text-align: center; padding: 1rem; background-color: #e8f5e9; border-radius: 10px;'>
                        <h2 style='color: #2e7d32;'>{confidence *100:.2f}%</h2>
                        <p style='font-size: 1.2rem;'>Confidence</p>
                    </div>
                """, unsafe_allow_html=True)

            # Display confidence bars
            st.markdown("<br><h3>Detailed Analysis</h3>", unsafe_allow_html=True)
            for label, prob in zip(labels, prediction[0]):
                st.markdown(f"<div class='confidence-bar'>", unsafe_allow_html=True)
                st.progress(float(prob))
                st.markdown(f"{label}: {float(prob)*100:.4f}%")
                st.markdown("</div>", unsafe_allow_html=True)

            # Generate and save saliency map
            if 'generate_saliency_map' in globals():
                try:
                    img_size = (160, 160)
                    box_map = generate_saliency_map(model, img_array, class_index, img_size)
                    
                    # Save saliency map
                    cv2.imwrite(saliency_path, cv2.cvtColor(box_map, cv2.COLOR_RGB2BGR))
                    st.write("DEBUG: Saved saliency map to:", saliency_path)

                    # Display images
                    display_cols = st.columns(2)
                    with display_cols[0]:
                        st.image(img_path, caption='Original Image', use_column_width=True)
                    with display_cols[1]:
                        st.image(box_map, caption='Tumor Detection with Bounding Box', use_column_width=True)

                    # Generate explanation using the saved saliency map
                    st.write("DEBUG: Attempting to generate explanation with path:", saliency_path)
                    try:
                        explanation = generate_explanation(saliency_path, predicted_class, confidence)
                        if explanation:
                            st.markdown("<h3>Expert Analysis:</h3>", unsafe_allow_html=True)
                            st.write(explanation)
                        else:
                            st.error("‚ùå Failed to generate an explanation.")
                    except Exception as e:
                        st.error(f"‚ùå Error in explanation generation: {str(e)}")
                        st.write("DEBUG: Error details:", str(e))

                except Exception as e:
                    st.error(f"‚ùå Error in saliency map generation: {str(e)}")
                    st.write("DEBUG: Full error:", str(e))

    except Exception as e:
        st.error(f"‚ùå An error occurred during processing: {str(e)}")
        st.write("DEBUG: Full error:", str(e))

st.markdown("</div>", unsafe_allow_html=True)
